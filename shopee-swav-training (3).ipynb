{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Self-supervised learning with fastai\n\nInspired by [Ayush Thakur's work](https://www.kaggle.com/ayuraj/v2-self-supervised-pretraining-with-swav?scriptVersionId=59516445), I started exploring more about SwAV. The results in the [paper](https://arxiv.org/abs/2006.09882) were quite impressive. Hence, I decided to implement it.\n\nLucky for me, I found a pytorch implementation. Also, it used fastai. This was like a dream come true. Fastai is my comfort zone. You can find more about the [implementation here](https://keremturgutlu.github.io/self_supervised/). I will highly recommend checking out the documentation. Not just SwAV, the repository has fastai implementations of other state-of-the-art algorithms as well.\n\nI followed [this tutorial](https://keremturgutlu.github.io/self_supervised/04%20-%20training_swav_iwang.html) for creating this notebook that you are reading now. So, if something looks off or doesn't make sense, then please refer the original tutorial.\n\nLets get started . . .","metadata":{"papermill":{"duration":0.013149,"end_time":"2021-04-24T18:22:25.065127","exception":false,"start_time":"2021-04-24T18:22:25.051978","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"### Installation & imports","metadata":{"papermill":{"duration":0.011883,"end_time":"2021-04-24T18:22:25.089945","exception":false,"start_time":"2021-04-24T18:22:25.078062","status":"completed"},"tags":[]}},{"cell_type":"code","source":"!pip install self-supervised -Uq","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":8.627421,"end_time":"2021-04-24T18:22:33.729432","exception":false,"start_time":"2021-04-24T18:22:25.102011","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-11T04:48:40.635260Z","iopub.execute_input":"2021-10-11T04:48:40.635553Z","iopub.status.idle":"2021-10-11T04:48:49.262035Z","shell.execute_reply.started":"2021-10-11T04:48:40.635527Z","shell.execute_reply":"2021-10-11T04:48:49.260874Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from fastai.vision.all import *\n\nfrom self_supervised.augmentations import *\nfrom self_supervised.layers import *\nfrom self_supervised.vision.swav import *\n\nfrom sklearn.model_selection import StratifiedKFold\nimport torchvision.models as models\nfrom cuml.neighbors import NearestNeighbors","metadata":{"papermill":{"duration":7.209293,"end_time":"2021-04-24T18:22:40.951377","exception":false,"start_time":"2021-04-24T18:22:33.742084","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-11T04:48:49.264263Z","iopub.execute_input":"2021-10-11T04:48:49.264794Z","iopub.status.idle":"2021-10-11T04:48:55.353239Z","shell.execute_reply.started":"2021-10-11T04:48:49.264742Z","shell.execute_reply":"2021-10-11T04:48:55.352449Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"### Reading Data","metadata":{"papermill":{"duration":0.012721,"end_time":"2021-04-24T18:22:40.977261","exception":false,"start_time":"2021-04-24T18:22:40.964540","status":"completed"},"tags":[]}},{"cell_type":"code","source":"df = pd.read_csv('../input/shopee-product-matching/train.csv')\ndf.head()","metadata":{"papermill":{"duration":0.218204,"end_time":"2021-04-24T18:22:41.207890","exception":false,"start_time":"2021-04-24T18:22:40.989686","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-11T04:48:55.354530Z","iopub.execute_input":"2021-10-11T04:48:55.354891Z","iopub.status.idle":"2021-10-11T04:48:55.552017Z","shell.execute_reply.started":"2021-10-11T04:48:55.354853Z","shell.execute_reply":"2021-10-11T04:48:55.551087Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"To train the model, we will also need a validation set. I will use simple `StratifiedKFold` technique to split my data into train & validation set.","metadata":{"papermill":{"duration":0.013435,"end_time":"2021-04-24T18:22:41.236205","exception":false,"start_time":"2021-04-24T18:22:41.222770","status":"completed"},"tags":[]}},{"cell_type":"code","source":"sk_fold = StratifiedKFold(5)\ndf['is_valid'] = False\nfor i, (trn_idx, val_idx) in enumerate(sk_fold.split(df, df.label_group)):\n    df.loc[val_idx, 'is_valid'] = True\n    break\n    \ndf.groupby('is_valid').label_group.value_counts()","metadata":{"papermill":{"duration":0.297002,"end_time":"2021-04-24T18:22:41.547218","exception":false,"start_time":"2021-04-24T18:22:41.250216","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-11T04:48:55.556127Z","iopub.execute_input":"2021-10-11T04:48:55.556482Z","iopub.status.idle":"2021-10-11T04:48:55.823393Z","shell.execute_reply.started":"2021-10-11T04:48:55.556452Z","shell.execute_reply":"2021-10-11T04:48:55.822599Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"As per the warning, there are some label groups with less than 5 posting. lets see how many such label group we have . . . ","metadata":{"papermill":{"duration":0.01454,"end_time":"2021-04-24T18:22:41.576472","exception":false,"start_time":"2021-04-24T18:22:41.561932","status":"completed"},"tags":[]}},{"cell_type":"code","source":"sum(df.label_group.value_counts() < 5)","metadata":{"papermill":{"duration":0.031906,"end_time":"2021-04-24T18:22:41.623048","exception":false,"start_time":"2021-04-24T18:22:41.591142","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-11T04:48:55.827051Z","iopub.execute_input":"2021-10-11T04:48:55.827307Z","iopub.status.idle":"2021-10-11T04:48:55.840603Z","shell.execute_reply.started":"2021-10-11T04:48:55.827283Z","shell.execute_reply":"2021-10-11T04:48:55.839740Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"There are 9620 `label_group` with less than 5 postings. Quite a lot, huh! (lets handle it in version-2).\n\n### Dataloaders\n\nFor now, lets create some helper functions to create dataloaders.","metadata":{"papermill":{"duration":0.013908,"end_time":"2021-04-24T18:22:41.651287","exception":false,"start_time":"2021-04-24T18:22:41.637379","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def get_x(x): return '../input/shopee-product-matching/train_images/' + x['image']\n\ndef get_dls(size, bs, workers=None):\n    path = Path('../input/shopee-product-matching/train_images/')\n    \n    db = DataBlock(blocks = (ImageBlock(), CategoryBlock()),\n              get_x = get_x, get_y=ColReader('label_group'),\n              splitter=ColSplitter(),\n              item_tfms=RandomResizedCrop(size, min_scale=1.))\n    dls = db.dataloaders(df, bs=bs, num_workers=workers)\n    return dls","metadata":{"papermill":{"duration":0.023448,"end_time":"2021-04-24T18:22:41.689029","exception":false,"start_time":"2021-04-24T18:22:41.665581","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-11T04:48:55.842349Z","iopub.execute_input":"2021-10-11T04:48:55.842698Z","iopub.status.idle":"2021-10-11T04:48:55.851366Z","shell.execute_reply.started":"2021-10-11T04:48:55.842664Z","shell.execute_reply":"2021-10-11T04:48:55.850610Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"Lets create our dataloaders . . . ","metadata":{"papermill":{"duration":0.014191,"end_time":"2021-04-24T18:22:41.717386","exception":false,"start_time":"2021-04-24T18:22:41.703195","status":"completed"},"tags":[]}},{"cell_type":"code","source":"bs, resize, size = 24, 256, 224\ndls = get_dls(resize, bs)","metadata":{"papermill":{"duration":10.803387,"end_time":"2021-04-24T18:22:52.535600","exception":false,"start_time":"2021-04-24T18:22:41.732213","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-11T04:48:55.853140Z","iopub.execute_input":"2021-10-11T04:48:55.853493Z","iopub.status.idle":"2021-10-11T04:49:06.201849Z","shell.execute_reply.started":"2021-10-11T04:48:55.853456Z","shell.execute_reply":"2021-10-11T04:49:06.201052Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"### Model & Callbacks\n\nFinally, lets initialize our model & SwAV callbacks","metadata":{"papermill":{"duration":0.01391,"end_time":"2021-04-24T18:22:52.563880","exception":false,"start_time":"2021-04-24T18:22:52.549970","status":"completed"},"tags":[]}},{"cell_type":"code","source":"## Model\narch = \"resnet50\"\nencoder = create_encoder(arch, pretrained=True, n_in=3)\nmodel = create_swav_model(encoder)\n\n## SwAV callback\nK = bs*2**4\naug_pipelines = get_swav_aug_pipelines(num_crops=[2, 6],\n                                       crop_sizes=[size,int(3/4*size)], \n                                       min_scales=[0.25, 0.20],\n                                       max_scales=[1.00, 0.35],\n                                       rotate=True, rotate_deg=10, jitter=True, bw=True, blur=False)\ncbs=[SWAV(aug_pipelines, crop_assgn_ids=[0,1], K=K, queue_start_pct=0.5, temp=0.1)]","metadata":{"papermill":{"duration":6.532105,"end_time":"2021-04-24T18:22:59.109932","exception":false,"start_time":"2021-04-24T18:22:52.577827","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-11T04:49:06.203173Z","iopub.execute_input":"2021-10-11T04:49:06.203502Z","iopub.status.idle":"2021-10-11T04:49:13.084167Z","shell.execute_reply.started":"2021-10-11T04:49:06.203468Z","shell.execute_reply":"2021-10-11T04:49:13.083194Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"Great, we have our data, model, & also the callbacks. Fastai has this amazing class called `Learner` which put everything together for training.","metadata":{"papermill":{"duration":0.014626,"end_time":"2021-04-24T18:22:59.140099","exception":false,"start_time":"2021-04-24T18:22:59.125473","status":"completed"},"tags":[]}},{"cell_type":"code","source":"learn = Learner(dls, model, cbs=cbs)","metadata":{"papermill":{"duration":0.022482,"end_time":"2021-04-24T18:22:59.177409","exception":false,"start_time":"2021-04-24T18:22:59.154927","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-11T04:49:13.085472Z","iopub.execute_input":"2021-10-11T04:49:13.085854Z","iopub.status.idle":"2021-10-11T04:49:13.091038Z","shell.execute_reply.started":"2021-10-11T04:49:13.085818Z","shell.execute_reply":"2021-10-11T04:49:13.089927Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"Before we actually training the model, lets look at some of the samples. ","metadata":{"papermill":{"duration":0.014633,"end_time":"2021-04-24T18:22:59.206765","exception":false,"start_time":"2021-04-24T18:22:59.192132","status":"completed"},"tags":[]}},{"cell_type":"code","source":"b = dls.one_batch()\nlearn._split(b)\nlearn('before_batch')\nlearn.swav.show(n=5);","metadata":{"papermill":{"duration":4.200808,"end_time":"2021-04-24T18:23:03.422903","exception":false,"start_time":"2021-04-24T18:22:59.222095","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-11T04:49:13.092969Z","iopub.execute_input":"2021-10-11T04:49:13.093398Z","iopub.status.idle":"2021-10-11T04:49:17.593035Z","shell.execute_reply.started":"2021-10-11T04:49:13.093363Z","shell.execute_reply":"2021-10-11T04:49:17.591941Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"### Training \n\nTime to train the model . . . ","metadata":{"papermill":{"duration":0.043019,"end_time":"2021-04-24T18:23:03.509103","exception":false,"start_time":"2021-04-24T18:23:03.466084","status":"completed"},"tags":[]}},{"cell_type":"code","source":"lr, wd = 1e-2, 1e-2\nepochs = 5 # try using 40 or 50\nlearn.unfreeze()\nlearn.fit_flat_cos(epochs, lr, wd=wd, pct_start=0.5)","metadata":{"papermill":{"duration":6053.723571,"end_time":"2021-04-24T20:03:57.275601","exception":false,"start_time":"2021-04-24T18:23:03.552030","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-11T04:49:17.594271Z","iopub.execute_input":"2021-10-11T04:49:17.594715Z","iopub.status.idle":"2021-10-11T06:30:30.379248Z","shell.execute_reply.started":"2021-10-11T04:49:17.594671Z","shell.execute_reply":"2021-10-11T06:30:30.377989Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"\nlearn.recorder.plot_loss()","metadata":{"papermill":{"duration":0.955062,"end_time":"2021-04-24T20:03:58.276262","exception":false,"start_time":"2021-04-24T20:03:57.321200","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-11T06:30:30.381296Z","iopub.execute_input":"2021-10-11T06:30:30.381696Z","iopub.status.idle":"2021-10-11T06:30:31.304209Z","shell.execute_reply.started":"2021-10-11T06:30:30.381656Z","shell.execute_reply":"2021-10-11T06:30:31.303326Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"save_name = f'swav_iwang_sz{size}_epc{epochs}'\n","metadata":{"execution":{"iopub.status.busy":"2021-10-11T06:37:56.867234Z","iopub.execute_input":"2021-10-11T06:37:56.867605Z","iopub.status.idle":"2021-10-11T06:37:56.871938Z","shell.execute_reply.started":"2021-10-11T06:37:56.867560Z","shell.execute_reply":"2021-10-11T06:37:56.870848Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"learn.save(save_name)\n","metadata":{"execution":{"iopub.status.busy":"2021-10-11T06:37:57.463846Z","iopub.execute_input":"2021-10-11T06:37:57.464171Z","iopub.status.idle":"2021-10-11T06:37:58.237401Z","shell.execute_reply.started":"2021-10-11T06:37:57.464135Z","shell.execute_reply":"2021-10-11T06:37:58.236390Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"!cd models","metadata":{"execution":{"iopub.status.busy":"2021-10-11T06:41:01.455716Z","iopub.execute_input":"2021-10-11T06:41:01.456056Z","iopub.status.idle":"2021-10-11T06:41:02.190904Z","shell.execute_reply.started":"2021-10-11T06:41:01.456028Z","shell.execute_reply":"2021-10-11T06:41:02.189819Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"!ls\n","metadata":{"execution":{"iopub.status.busy":"2021-10-11T06:41:04.160611Z","iopub.execute_input":"2021-10-11T06:41:04.161099Z","iopub.status.idle":"2021-10-11T06:41:04.881064Z","shell.execute_reply.started":"2021-10-11T06:41:04.161061Z","shell.execute_reply":"2021-10-11T06:41:04.879960Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"cd models","metadata":{"execution":{"iopub.status.busy":"2021-10-11T06:41:17.244762Z","iopub.execute_input":"2021-10-11T06:41:17.245099Z","iopub.status.idle":"2021-10-11T06:41:17.252420Z","shell.execute_reply.started":"2021-10-11T06:41:17.245071Z","shell.execute_reply":"2021-10-11T06:41:17.251571Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"ls","metadata":{"execution":{"iopub.status.busy":"2021-10-11T06:41:28.540308Z","iopub.execute_input":"2021-10-11T06:41:28.540660Z","iopub.status.idle":"2021-10-11T06:41:29.260352Z","shell.execute_reply.started":"2021-10-11T06:41:28.540622Z","shell.execute_reply":"2021-10-11T06:41:29.259216Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"ls /kaggle/working/models/swav_iwang_sz224_epc5_encoder.pth","metadata":{"execution":{"iopub.status.busy":"2021-10-11T06:43:29.799115Z","iopub.execute_input":"2021-10-11T06:43:29.799478Z","iopub.status.idle":"2021-10-11T06:43:30.535037Z","shell.execute_reply.started":"2021-10-11T06:43:29.799447Z","shell.execute_reply":"2021-10-11T06:43:30.533831Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"cp swav_iwang_sz224_epc5_encoder.pth ../input/shopee-product-matching","metadata":{"execution":{"iopub.status.busy":"2021-10-11T06:42:39.489209Z","iopub.execute_input":"2021-10-11T06:42:39.489556Z","iopub.status.idle":"2021-10-11T06:42:40.210615Z","shell.execute_reply.started":"2021-10-11T06:42:39.489526Z","shell.execute_reply":"2021-10-11T06:42:40.209598Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"torch.save(learn.model.encoder.state_dict(), learn.path/learn.model_dir/f'{save_name}_encoder.pth')","metadata":{"execution":{"iopub.status.busy":"2021-10-11T06:38:40.124290Z","iopub.execute_input":"2021-10-11T06:38:40.124625Z","iopub.status.idle":"2021-10-11T06:38:40.376441Z","shell.execute_reply.started":"2021-10-11T06:38:40.124581Z","shell.execute_reply":"2021-10-11T06:38:40.375315Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"while true:\n    pass","metadata":{"execution":{"iopub.status.busy":"2021-10-11T06:30:31.308163Z","iopub.execute_input":"2021-10-11T06:30:31.308513Z","iopub.status.idle":"2021-10-11T06:37:15.837003Z","shell.execute_reply.started":"2021-10-11T06:30:31.308476Z","shell.execute_reply":"2021-10-11T06:37:15.835644Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"This notebook is only intended for learning. To get better score, try using different model architecture, bigger image size, etc.\n\nI can find the inference notebook, [here](https://www.kaggle.com/ankursingh12/shopee-swav-inference)\n\nHope you enjoyed reading this notebook. If yes, then please consider **upvoting**!","metadata":{"papermill":{"duration":0.042953,"end_time":"2021-04-24T20:03:58.362918","exception":false,"start_time":"2021-04-24T20:03:58.319965","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import sys\nsys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')","metadata":{"execution":{"iopub.status.busy":"2021-10-11T06:43:51.593814Z","iopub.execute_input":"2021-10-11T06:43:51.594150Z","iopub.status.idle":"2021-10-11T06:43:51.598607Z","shell.execute_reply.started":"2021-10-11T06:43:51.594120Z","shell.execute_reply":"2021-10-11T06:43:51.597497Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"import gc\nimport os \nimport cv2\nimport timm\nimport random\n\nimport numpy as np \nimport pandas as pd \nfrom tqdm import tqdm\nfrom pathlib import Path\n\nimport torch\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom self_supervised.augmentations import *\nfrom self_supervised.layers import *\nfrom self_supervised.vision.swav import *\n\nimport torchvision.models as models\nfrom cuml.neighbors import NearestNeighbors\n\nimport albumentations as A \nfrom albumentations.pytorch.transforms import ToTensorV2","metadata":{"execution":{"iopub.status.busy":"2021-10-11T06:43:54.389639Z","iopub.execute_input":"2021-10-11T06:43:54.389972Z","iopub.status.idle":"2021-10-11T06:43:55.469874Z","shell.execute_reply.started":"2021-10-11T06:43:54.389944Z","shell.execute_reply":"2021-10-11T06:43:55.469008Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"path = Path('../input/shopee-product-matching')\n\n\nclass CFG:\n    img_size = 512\n    batch_size = 12\n    seed = 2020\n    \n    device = 'cuda'\n    classes = 11014\n    \n    scale = 30 \n    margin = 0.5","metadata":{"execution":{"iopub.status.busy":"2021-10-11T06:43:59.322466Z","iopub.execute_input":"2021-10-11T06:43:59.322893Z","iopub.status.idle":"2021-10-11T06:43:59.329950Z","shell.execute_reply.started":"2021-10-11T06:43:59.322858Z","shell.execute_reply":"2021-10-11T06:43:59.328651Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"def seed_torch(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    \nseed_torch(CFG.seed)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T06:44:02.401657Z","iopub.execute_input":"2021-10-11T06:44:02.402021Z","iopub.status.idle":"2021-10-11T06:44:02.409626Z","shell.execute_reply.started":"2021-10-11T06:44:02.401991Z","shell.execute_reply":"2021-10-11T06:44:02.406992Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"def read_dataset():\n    df = pd.read_csv('../input/shopee-product-matching/train.csv')\n    tmp = df.groupby('label_group').posting_id.agg('unique').to_dict()\n    df['target'] = df.label_group.map(tmp)\n    \n    image_paths = str(path) + '/train_images/' + df['image']\n    return df, image_paths\n\ndef get_test_transforms():\n    return A.Compose([A.Resize(CFG.img_size, CFG.img_size, always_apply=True),\n                      A.Normalize(), ToTensorV2(p=1.0)])\n\nclass ShopeeDataset(Dataset):\n    def __init__(self, image_paths, transforms=None):\n        self.image_paths = image_paths\n        self.augmentations = transforms\n\n    def __len__(self):\n        return self.image_paths.shape[0]\n\n    def __getitem__(self, index):\n        image_path = self.image_paths[index]\n        image = cv2.imread(image_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        if self.augmentations:\n            augmented = self.augmentations(image=image)\n            image = augmented['image']       \n    \n        return image,torch.tensor(1)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T06:47:46.973016Z","iopub.execute_input":"2021-10-11T06:47:46.973337Z","iopub.status.idle":"2021-10-11T06:47:46.981695Z","shell.execute_reply.started":"2021-10-11T06:47:46.973308Z","shell.execute_reply":"2021-10-11T06:47:46.980819Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"def get_image_embeddings(image_paths, model, model_path=None):\n    embeds = []\n    model.eval()\n    \n    if model_path:\n        model.load_state_dict(torch.load(model_path))\n        model = model.to(CFG.device)\n    \n    image_dataset = ShopeeDataset(image_paths,transforms = get_test_transforms())\n    image_loader = DataLoader(image_dataset, batch_size=CFG.batch_size, pin_memory=True, \n                              drop_last=False,num_workers=4)\n    \n    with torch.no_grad():\n        for img,label in tqdm(image_loader): \n            img = img.cuda()\n            feat = model(img)\n            image_embeddings = feat.detach().cpu().numpy()\n            embeds.append(image_embeddings)\n            \n    image_embeddings = np.concatenate(embeds)\n    print(f'Our image embeddings shape is {image_embeddings.shape}')\n    \n    del embeds, model\n    gc.collect()\n    return image_embeddings\n\n\ndef get_image_predictions(df, embeddings,threshold = 0.0):\n    if len(df) > 3: KNN = 50\n    else : KNN = 3\n    \n    model = NearestNeighbors(n_neighbors = KNN, metric = 'euclidean')\n    model.fit(embeddings)\n    distances, indices = model.kneighbors(embeddings)\n    \n    predictions = []\n    for k in tqdm(range(embeddings.shape[0])):\n        idx = np.where(distances[k,] < threshold)[0]\n        ids = indices[k,idx]\n        posting_ids = df['posting_id'].iloc[ids].values\n        predictions.append(posting_ids)\n        \n    del model, distances, indices\n    gc.collect()\n    return predictions","metadata":{"execution":{"iopub.status.busy":"2021-10-11T06:47:49.217915Z","iopub.execute_input":"2021-10-11T06:47:49.218255Z","iopub.status.idle":"2021-10-11T06:47:49.228707Z","shell.execute_reply.started":"2021-10-11T06:47:49.218223Z","shell.execute_reply":"2021-10-11T06:47:49.227735Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"def combine_predictions(row):\n    x = np.concatenate([row['image_predictions']])\n    return ' '.join( np.unique(x))\n\ndef getMetric(row, col):\n        n = len(np.intersect1d(row.target,row[col]))\n        return 2*n / (len(row.target)+len(row[col]))\n    \ndef evaluate_model(models):\n    img_embeddings = 0\n    \n    if isinstance(models, list):\n        for m in models:\n            img_embeddings += get_image_embeddings(image_paths.values, m)\n        img_embeddings /= len(models)\n    else:\n        img_embeddings = get_image_embeddings(image_paths.values, models)\n        \n    img_embeddings = img_embeddings.squeeze()\n    image_predictions = get_image_predictions(df, img_embeddings, threshold = 0.36)\n    \n    df['image_predictions'] = image_predictions\n    f1_scores = df.apply(lambda r: getMetric(r, 'image_predictions'), axis=1)\n    print(f'CV score for baseline = {f1_scores.mean()}')\n","metadata":{"execution":{"iopub.status.busy":"2021-10-11T06:47:49.820266Z","iopub.execute_input":"2021-10-11T06:47:49.820582Z","iopub.status.idle":"2021-10-11T06:47:49.829371Z","shell.execute_reply.started":"2021-10-11T06:47:49.820552Z","shell.execute_reply":"2021-10-11T06:47:49.828445Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"df,image_paths = read_dataset()\ndf.head()\n","metadata":{"execution":{"iopub.status.busy":"2021-10-11T06:47:50.787151Z","iopub.execute_input":"2021-10-11T06:47:50.787479Z","iopub.status.idle":"2021-10-11T06:47:50.846521Z","shell.execute_reply.started":"2021-10-11T06:47:50.787450Z","shell.execute_reply":"2021-10-11T06:47:50.844521Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"## Pretrained Resnet50 from pytorch\nmodel = models.resnet50(pretrained=True)\nmodel_enc = torch.nn.Sequential(*(list(model.children())[:-1])).cuda()\nmodel_enc.eval()\nevaluate_model(model_enc)\n# euclidean -  CV score = 0.4930072045298856","metadata":{"execution":{"iopub.status.busy":"2021-10-11T06:45:59.837157Z","iopub.execute_input":"2021-10-11T06:45:59.837489Z","iopub.status.idle":"2021-10-11T06:46:00.557226Z","shell.execute_reply.started":"2021-10-11T06:45:59.837457Z","shell.execute_reply":"2021-10-11T06:46:00.555728Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"## Resnet50 trained using SwAV, by faceboook\nmodel = torch.hub.load('facebookresearch/swav', 'resnet50')\nmodel_enc = torch.nn.Sequential(*(list(model.children())[:-1])).cuda()\nmodel_enc.eval()\nevaluate_model(model_enc)\n# euclidean - CV score = 0.5134202771430936","metadata":{"execution":{"iopub.status.busy":"2021-10-11T06:46:07.204473Z","iopub.execute_input":"2021-10-11T06:46:07.204816Z","iopub.status.idle":"2021-10-11T06:46:07.954440Z","shell.execute_reply.started":"2021-10-11T06:46:07.204785Z","shell.execute_reply":"2021-10-11T06:46:07.951276Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"## Fine-tuned Resnet50\narch = 'resnet50'\nencoder_path = '/kaggle/working/models/swav_iwang_sz224_epc5_encoder.pth'\nencoder = create_encoder(arch, pretrained=False, n_in=3)\nencoder.load_state_dict(torch.load(encoder_path))\nencoder.cuda()\nencoder.eval()\nevaluate_model(encoder)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T06:51:43.423025Z","iopub.execute_input":"2021-10-11T06:51:43.423375Z","iopub.status.idle":"2021-10-11T06:51:44.051277Z","shell.execute_reply.started":"2021-10-11T06:51:43.423341Z","shell.execute_reply":"2021-10-11T06:51:44.049836Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}