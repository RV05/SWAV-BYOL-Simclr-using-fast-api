{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Self-supervised learning with fastai\n\nInspired by [Ayush Thakur's work](https://www.kaggle.com/ayuraj/v2-self-supervised-pretraining-with-swav?scriptVersionId=59516445), I started exploring more about SwAV. The results in the [paper](https://arxiv.org/abs/2006.09882) were quite impressive. Hence, I decided to implement it.\n\nLucky for me, I found a pytorch implementation. Also, it used fastai. This was like a dream come true. Fastai is my comfort zone. You can find more about the [implementation here](https://keremturgutlu.github.io/self_supervised/). I will highly recommend checking out the documentation. Not just SwAV, the repository has fastai implementations of other state-of-the-art algorithms as well.\n\nI followed [this tutorial](https://keremturgutlu.github.io/self_supervised/04%20-%20training_swav_iwang.html) for creating this notebook that you are reading now. So, if something looks off or doesn't make sense, then please refer the original tutorial.\n\nLets get started . . .","metadata":{}},{"cell_type":"markdown","source":"### Installation & imports","metadata":{}},{"cell_type":"code","source":"!pip install self-supervised -Uq","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-11T12:21:52.090320Z","iopub.execute_input":"2021-10-11T12:21:52.090663Z","iopub.status.idle":"2021-10-11T12:22:03.066379Z","shell.execute_reply.started":"2021-10-11T12:21:52.090626Z","shell.execute_reply":"2021-10-11T12:22:03.064842Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from fastai.vision.all import *\n\nfrom self_supervised.augmentations import *\nfrom self_supervised.layers import *\nfrom self_supervised.vision.swav import *\n\nfrom sklearn.model_selection import StratifiedKFold\nimport torchvision.models as models\nfrom cuml.neighbors import NearestNeighbors","metadata":{"execution":{"iopub.status.busy":"2021-10-11T12:22:03.070963Z","iopub.execute_input":"2021-10-11T12:22:03.071368Z","iopub.status.idle":"2021-10-11T12:22:10.757113Z","shell.execute_reply.started":"2021-10-11T12:22:03.071337Z","shell.execute_reply":"2021-10-11T12:22:10.756135Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"### Reading Data","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/shopee-product-matching/train.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-11T12:22:10.758881Z","iopub.execute_input":"2021-10-11T12:22:10.759325Z","iopub.status.idle":"2021-10-11T12:22:10.947769Z","shell.execute_reply.started":"2021-10-11T12:22:10.759284Z","shell.execute_reply":"2021-10-11T12:22:10.946556Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"To train the model, we will also need a validation set. I will use simple `StratifiedKFold` technique to split my data into train & validation set.","metadata":{}},{"cell_type":"code","source":"sk_fold = StratifiedKFold(5)\ndf['is_valid'] = False\nfor i, (trn_idx, val_idx) in enumerate(sk_fold.split(df, df.label_group)):\n    df.loc[val_idx, 'is_valid'] = True\n    break\n    \ndf.groupby('is_valid').label_group.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-10-11T12:22:10.949354Z","iopub.execute_input":"2021-10-11T12:22:10.949897Z","iopub.status.idle":"2021-10-11T12:22:11.331877Z","shell.execute_reply.started":"2021-10-11T12:22:10.949823Z","shell.execute_reply":"2021-10-11T12:22:11.330221Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"As per the warning, there are some label groups with less than 5 posting. lets see how many such label group we have . . . ","metadata":{}},{"cell_type":"code","source":"sum(df.label_group.value_counts() < 5)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T12:22:11.336030Z","iopub.execute_input":"2021-10-11T12:22:11.336452Z","iopub.status.idle":"2021-10-11T12:22:11.354928Z","shell.execute_reply.started":"2021-10-11T12:22:11.336416Z","shell.execute_reply":"2021-10-11T12:22:11.353622Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"There are 9620 `label_group` with less than 5 postings. Quite a lot, huh! (lets handle it in version-2).\n\n### Dataloaders\n\nFor now, lets create some helper functions to create dataloaders.","metadata":{}},{"cell_type":"code","source":"def get_x(x): return '../input/shopee-product-matching/train_images/' + x['image']\n\ndef get_dls(size, bs, workers=None):\n    path = Path('../input/shopee-product-matching/train_images/')\n    \n    db = DataBlock(blocks = (ImageBlock(), CategoryBlock()),\n              get_x = get_x, get_y=ColReader('label_group'),\n              splitter=ColSplitter(),\n              item_tfms=RandomResizedCrop(size, min_scale=1.))\n    dls = db.dataloaders(df, bs=bs, num_workers=workers)\n    return dls","metadata":{"execution":{"iopub.status.busy":"2021-10-11T12:22:11.356906Z","iopub.execute_input":"2021-10-11T12:22:11.357333Z","iopub.status.idle":"2021-10-11T12:22:11.364732Z","shell.execute_reply.started":"2021-10-11T12:22:11.357295Z","shell.execute_reply":"2021-10-11T12:22:11.363377Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"Lets create our dataloaders . . . ","metadata":{}},{"cell_type":"code","source":"bs, resize, size = 24, 256, 224\ndls = get_dls(resize, bs)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T12:22:11.367670Z","iopub.execute_input":"2021-10-11T12:22:11.368475Z","iopub.status.idle":"2021-10-11T12:22:25.247019Z","shell.execute_reply.started":"2021-10-11T12:22:11.368140Z","shell.execute_reply":"2021-10-11T12:22:25.245607Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"### Model & Callbacks\n\nFinally, lets initialize our model & SwAV callbacks","metadata":{}},{"cell_type":"code","source":"## Model\narch = \"resnet50\"\nencoder = create_encoder(arch, pretrained=True, n_in=3)\nmodel = create_swav_model(encoder)\n\n## SwAV callback\nK = bs*2**4\naug_pipelines = get_swav_aug_pipelines(num_crops=[2, 6],\n                                       crop_sizes=[size,int(3/4*size)], \n                                       min_scales=[0.25, 0.20],\n                                       max_scales=[1.00, 0.35],\n                                       rotate=True, rotate_deg=10, jitter=True, bw=True, blur=False)\ncbs=[SWAV(aug_pipelines, crop_assgn_ids=[0,1], K=K, queue_start_pct=0.5, temp=0.1)]","metadata":{"execution":{"iopub.status.busy":"2021-10-11T12:22:25.248642Z","iopub.execute_input":"2021-10-11T12:22:25.249029Z","iopub.status.idle":"2021-10-11T12:22:27.811000Z","shell.execute_reply.started":"2021-10-11T12:22:25.248988Z","shell.execute_reply":"2021-10-11T12:22:27.809795Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"Great, we have our data, model, & also the callbacks. Fastai has this amazing class called `Learner` which put everything together for training.","metadata":{}},{"cell_type":"code","source":"learn = Learner(dls, model, cbs=cbs)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T12:22:27.812556Z","iopub.execute_input":"2021-10-11T12:22:27.813152Z","iopub.status.idle":"2021-10-11T12:22:27.821224Z","shell.execute_reply.started":"2021-10-11T12:22:27.812990Z","shell.execute_reply":"2021-10-11T12:22:27.819386Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"Before we actually training the model, lets look at some of the samples. ","metadata":{}},{"cell_type":"code","source":"b = dls.one_batch()\nlearn._split(b)\nlearn('before_batch')\nlearn.swav.show(n=5);","metadata":{"execution":{"iopub.status.busy":"2021-10-11T12:22:27.823422Z","iopub.execute_input":"2021-10-11T12:22:27.824147Z","iopub.status.idle":"2021-10-11T12:22:33.066487Z","shell.execute_reply.started":"2021-10-11T12:22:27.824105Z","shell.execute_reply":"2021-10-11T12:22:33.065055Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"### Training \n\nTime to train the model . . . ","metadata":{}},{"cell_type":"code","source":"lr, wd = 1e-2, 1e-2\nepochs = 5 # try using 40 or 50\nlearn.unfreeze()\nlearn.fit_flat_cos(epochs, lr, wd=wd, pct_start=0.5)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T12:22:33.068056Z","iopub.execute_input":"2021-10-11T12:22:33.068475Z","iopub.status.idle":"2021-10-11T14:15:08.934299Z","shell.execute_reply.started":"2021-10-11T12:22:33.068435Z","shell.execute_reply":"2021-10-11T14:15:08.933020Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"save_name = f'swav_iwang_sz{size}_epc{epochs}'\nlearn.save(save_name)\ntorch.save(learn.model.encoder.state_dict(), learn.path/learn.model_dir/f'{save_name}_encoder.pth')\nlearn.recorder.plot_loss()","metadata":{"execution":{"iopub.status.busy":"2021-10-11T14:15:08.936424Z","iopub.execute_input":"2021-10-11T14:15:08.936950Z","iopub.status.idle":"2021-10-11T14:15:09.971744Z","shell.execute_reply.started":"2021-10-11T14:15:08.936902Z","shell.execute_reply":"2021-10-11T14:15:09.970583Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"while True:\n    pass","metadata":{"execution":{"iopub.status.busy":"2021-10-11T14:15:09.974805Z","iopub.execute_input":"2021-10-11T14:15:09.975296Z","iopub.status.idle":"2021-10-11T14:17:13.444937Z","shell.execute_reply.started":"2021-10-11T14:15:09.975250Z","shell.execute_reply":"2021-10-11T14:17:13.442705Z"},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":true},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This notebook is only intended for learning. To get better score, try using different model architecture, bigger image size, etc.\n\nI can find the inference notebook, [here](https://www.kaggle.com/ankursingh12/shopee-swav-inference)\n\nHope you enjoyed reading this notebook. If yes, then please consider **upvoting**!","metadata":{}}]}