{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Self-supervised learning with fastai\n\nInspired by [Ayush Thakur's work](https://www.kaggle.com/ayuraj/v2-self-supervised-pretraining-with-swav?scriptVersionId=59516445), I started exploring more about SwAV. The results in the [paper](https://arxiv.org/abs/2006.09882) were quite impressive. Hence, I decided to implement it.\n\nLucky for me, I found a pytorch implementation. Also, it used fastai. This was like a dream come true. Fastai is my comfort zone. You can find more about the [implementation here](https://keremturgutlu.github.io/self_supervised/). I will highly recommend checking out the documentation. Not just SwAV, the repository has fastai implementations of other state-of-the-art algorithms as well.\n\nI followed [this tutorial](https://keremturgutlu.github.io/self_supervised/04%20-%20training_swav_iwang.html) for creating this notebook that you are reading now. So, if something looks off or doesn't make sense, then please refer the original tutorial.\n\nLets get started . . .","metadata":{}},{"cell_type":"markdown","source":"### Installation & imports","metadata":{}},{"cell_type":"code","source":"!pip install self-supervised -Uq","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-10-11T12:21:52.090320Z","iopub.execute_input":"2021-10-11T12:21:52.090663Z","iopub.status.idle":"2021-10-11T12:22:03.066379Z","shell.execute_reply.started":"2021-10-11T12:21:52.090626Z","shell.execute_reply":"2021-10-11T12:22:03.064842Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from fastai.vision.all import *\n\nfrom self_supervised.augmentations import *\nfrom self_supervised.layers import *\nfrom self_supervised.vision.swav import *\nfrom self_supervised.vision.byol import *\n\nfrom sklearn.model_selection import StratifiedKFold\nimport torchvision.models as models\nfrom cuml.neighbors import NearestNeighbors","metadata":{"execution":{"iopub.status.busy":"2021-10-11T14:24:39.358827Z","iopub.execute_input":"2021-10-11T14:24:39.359208Z","iopub.status.idle":"2021-10-11T14:24:39.369717Z","shell.execute_reply.started":"2021-10-11T14:24:39.359176Z","shell.execute_reply":"2021-10-11T14:24:39.368599Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"### Reading Data","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/shopee-product-matching/train.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-11T12:22:10.758881Z","iopub.execute_input":"2021-10-11T12:22:10.759325Z","iopub.status.idle":"2021-10-11T12:22:10.947769Z","shell.execute_reply.started":"2021-10-11T12:22:10.759284Z","shell.execute_reply":"2021-10-11T12:22:10.946556Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"To train the model, we will also need a validation set. I will use simple `StratifiedKFold` technique to split my data into train & validation set.","metadata":{}},{"cell_type":"code","source":"sk_fold = StratifiedKFold(5)\ndf['is_valid'] = False\nfor i, (trn_idx, val_idx) in enumerate(sk_fold.split(df, df.label_group)):\n    df.loc[val_idx, 'is_valid'] = True\n    break\n    \ndf.groupby('is_valid').label_group.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-10-11T12:22:10.949354Z","iopub.execute_input":"2021-10-11T12:22:10.949897Z","iopub.status.idle":"2021-10-11T12:22:11.331877Z","shell.execute_reply.started":"2021-10-11T12:22:10.949823Z","shell.execute_reply":"2021-10-11T12:22:11.330221Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"As per the warning, there are some label groups with less than 5 posting. lets see how many such label group we have . . . ","metadata":{}},{"cell_type":"code","source":"sum(df.label_group.value_counts() < 5)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T12:22:11.336030Z","iopub.execute_input":"2021-10-11T12:22:11.336452Z","iopub.status.idle":"2021-10-11T12:22:11.354928Z","shell.execute_reply.started":"2021-10-11T12:22:11.336416Z","shell.execute_reply":"2021-10-11T12:22:11.353622Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"There are 9620 `label_group` with less than 5 postings. Quite a lot, huh! (lets handle it in version-2).\n\n### Dataloaders\n\nFor now, lets create some helper functions to create dataloaders.","metadata":{}},{"cell_type":"code","source":"def get_x(x): return '../input/shopee-product-matching/train_images/' + x['image']\n\ndef get_dls(size, bs, workers=None):\n    path = Path('../input/shopee-product-matching/train_images/')\n    \n    db = DataBlock(blocks = (ImageBlock(), CategoryBlock()),\n              get_x = get_x, get_y=ColReader('label_group'),\n              splitter=ColSplitter(),\n              item_tfms=RandomResizedCrop(size, min_scale=1.))\n    dls = db.dataloaders(df, bs=bs, num_workers=workers)\n    return dls","metadata":{"execution":{"iopub.status.busy":"2021-10-11T12:22:11.356906Z","iopub.execute_input":"2021-10-11T12:22:11.357333Z","iopub.status.idle":"2021-10-11T12:22:11.364732Z","shell.execute_reply.started":"2021-10-11T12:22:11.357295Z","shell.execute_reply":"2021-10-11T12:22:11.363377Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"Lets create our dataloaders . . . ","metadata":{}},{"cell_type":"code","source":"bs, resize, size = 24, 256, 224\ndls = get_dls(resize, bs)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T12:22:11.367670Z","iopub.execute_input":"2021-10-11T12:22:11.368475Z","iopub.status.idle":"2021-10-11T12:22:25.247019Z","shell.execute_reply.started":"2021-10-11T12:22:11.368140Z","shell.execute_reply":"2021-10-11T12:22:25.245607Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"### Model & Callbacks\n\nFinally, lets initialize our model & SwAV callbacks","metadata":{}},{"cell_type":"code","source":"from self_supervised.vision.simclr import *\n## Model\narch = \"resnet50\"\nencoder = create_encoder(arch, pretrained=True, n_in=3)\nmodel = create_simclr_model(encoder, hidden_size=2048, projection_size=128)\n\n## SwAV callback\nK = bs*2**4\naug_pipelines = get_byol_aug_pipelines(size=size)\ncbs=[SimCLR(aug_pipelines=aug_pipelines)]","metadata":{"execution":{"iopub.status.busy":"2021-10-11T16:37:08.244433Z","iopub.execute_input":"2021-10-11T16:37:08.244855Z","iopub.status.idle":"2021-10-11T16:37:09.519372Z","shell.execute_reply.started":"2021-10-11T16:37:08.244823Z","shell.execute_reply":"2021-10-11T16:37:09.518258Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"Great, we have our data, model, & also the callbacks. Fastai has this amazing class called `Learner` which put everything together for training.","metadata":{}},{"cell_type":"code","source":"learn = Learner(dls, model, cbs=cbs)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T16:37:13.438284Z","iopub.execute_input":"2021-10-11T16:37:13.438683Z","iopub.status.idle":"2021-10-11T16:37:13.444806Z","shell.execute_reply.started":"2021-10-11T16:37:13.438656Z","shell.execute_reply":"2021-10-11T16:37:13.443497Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"Before we actually training the model, lets look at some of the samples. ","metadata":{}},{"cell_type":"code","source":"b = dls.one_batch()\nlearn._split(b)\n# learn('before_batch')\n# learn.byol.show(n=5);","metadata":{"execution":{"iopub.status.busy":"2021-10-11T16:37:14.837433Z","iopub.execute_input":"2021-10-11T16:37:14.837815Z","iopub.status.idle":"2021-10-11T16:37:15.249818Z","shell.execute_reply.started":"2021-10-11T16:37:14.837786Z","shell.execute_reply":"2021-10-11T16:37:15.248742Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"### Training \n\nTime to train the model . . . ","metadata":{}},{"cell_type":"code","source":"lr, wd = 1e-2, 1e-2\nepochs = 5 # try using 40 or 50\nlearn.unfreeze()\nlearn.fit_flat_cos(epochs, lr, wd=wd, pct_start=0.5)","metadata":{"execution":{"iopub.status.busy":"2021-10-11T16:37:17.837047Z","iopub.execute_input":"2021-10-11T16:37:17.837399Z","iopub.status.idle":"2021-10-11T17:29:12.093999Z","shell.execute_reply.started":"2021-10-11T16:37:17.837369Z","shell.execute_reply":"2021-10-11T17:29:12.092560Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"save_name = f'simclr_iwang_sz{size}_epc{epochs}'\nlearn.save(save_name)\ntorch.save(learn.model.encoder.state_dict(), learn.path/learn.model_dir/f'{save_name}_encoder.pth')\nlearn.recorder.plot_loss()","metadata":{"execution":{"iopub.status.busy":"2021-10-11T17:29:12.098237Z","iopub.execute_input":"2021-10-11T17:29:12.098562Z","iopub.status.idle":"2021-10-11T17:29:13.288433Z","shell.execute_reply.started":"2021-10-11T17:29:12.098535Z","shell.execute_reply":"2021-10-11T17:29:13.287165Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"ls","metadata":{"execution":{"iopub.status.busy":"2021-10-11T16:05:06.654452Z","iopub.execute_input":"2021-10-11T16:05:06.654889Z","iopub.status.idle":"2021-10-11T16:05:07.442672Z","shell.execute_reply.started":"2021-10-11T16:05:06.654856Z","shell.execute_reply":"2021-10-11T16:05:07.441398Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"while True:\n    pass","metadata":{"execution":{"iopub.status.busy":"2021-10-11T17:31:05.896914Z","iopub.execute_input":"2021-10-11T17:31:05.897320Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This notebook is only intended for learning. To get better score, try using different model architecture, bigger image size, etc.\n\nI can find the inference notebook, [here](https://www.kaggle.com/ankursingh12/shopee-swav-inference)\n\nHope you enjoyed reading this notebook. If yes, then please consider **upvoting**!","metadata":{}}]}